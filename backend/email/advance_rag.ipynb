{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "from urllib.parse import urlparse, parse_qs, urlunparse, urlencode, parse_qsl   \n",
    "from backend.openai_client import init_openai_client  \n",
    "from azure.identity.aio import DefaultAzureCredential  \n",
    "from azure.search.documents.aio import SearchClient  \n",
    "from azure.search.documents.models import QueryType, VectorizedQuery, QueryAnswerType, QueryCaptionType  \n",
    "from typing import List, Any\n",
    "from pydantic import BaseModel, Field\n",
    "import openai\n",
    "from backend.auth.auth_utils import get_authenticated_user_details\n",
    "from backend.security.ms_defender_utils import get_msdefender_user_json\n",
    "import json\n",
    "import logging\n",
    "import base64 \n",
    "import re\n",
    "import instructor\n",
    "import enum\n",
    "import asyncio\n",
    "# import asyncio\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "class AnswerCitation(BaseModel):\n",
    "    \"\"\" \n",
    "    Citations and Answer\n",
    "    \"\"\" \n",
    "    citation: List[List[str]] = Field([], description=\"Always include all the citations. in case of no answer citation=[[]] \")\n",
    "    \n",
    "    answer: str = Field(description=\"Only include Answer, do not include any citations in this. In case of no answer, answer = 'There is no answer available'\") \n",
    "  \n",
    "class Labels(str, enum.Enum):\n",
    "    YES = \"Yes\"\n",
    "    NO = \"No\"\n",
    "    \n",
    "class SinglePrediction(BaseModel):\n",
    "    class_label: Labels\n",
    "\n",
    "class AzureSearchPromptService:  \n",
    "    def __init__(self):  \n",
    "        self.service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
    "        self.wiki_index = os.getenv(\"AZURE_SEARCH_INDEX_VIDEO\")  #AZURE_SEARCH_INDEX_VIDEO\n",
    "        self.embedding_model = os.environ.get(\"AZURE_OPENAI_EMBEDDING_NAME\")  \n",
    "        self.chat_model = os.environ.get(\"AZURE_OPENAI_MODEL\")\n",
    "        self.MS_DEFENDER_ENABLED = os.environ.get(\"MS_DEFENDER_ENABLED\", \"true\").lower() == \"true\"\n",
    "  \n",
    "    async def generate_embeddings(self, query, model):\n",
    "        azure_openai_client = await init_openai_client()\n",
    "        embeddings_response = await azure_openai_client.embeddings.create(model=model, input=query)\n",
    "        embedding = embeddings_response.data[0].embedding\n",
    "        return embedding\n",
    "    \n",
    "    async def generate_vector_query(self, query: str) -> VectorizedQuery:  \n",
    "        vector = await self.generate_embeddings(query, self.embedding_model)  \n",
    "        return VectorizedQuery(vector=vector, k_nearest_neighbors=3, fields=\"text_vector\")  \n",
    "  \n",
    "    async def search(self, query: str, top: int = 3, rag_filter_query = None) -> List[Any]:  \n",
    "        vector_filter_mode = None\n",
    "        if rag_filter_query is not None:\n",
    "            vector_filter_mode=\"preFilter\"\n",
    "        async with SearchClient(self.service_endpoint, self.wiki_index, DefaultAzureCredential()) as search_client:\n",
    "            vector_query = await self.generate_vector_query(query)  \n",
    "            contexts = await search_client.search(  \n",
    "                search_text=query,  \n",
    "                vector_queries=[vector_query],  \n",
    "                select=[\"title\", \"chunk\", \"url_metadata\", \"file_name_metadata\", \"type\"],  #todo\n",
    "                # query_type=QueryType.SEMANTIC,\n",
    "                vector_filter_mode=vector_filter_mode,\n",
    "                filter=rag_filter_query,\n",
    "                semantic_configuration_name=\"semantic\",  \n",
    "                # query_caption=QueryCaptionType.EXTRACTIVE,  \n",
    "                # query_answer=QueryAnswerType.EXTRACTIVE,  \n",
    "                top=top  \n",
    "            )\n",
    "\n",
    "            return [context async for context in contexts]  \n",
    "        \n",
    "    @staticmethod\n",
    "    def get_filter_query(rag_filter):\n",
    "        return f\"type eq '{rag_filter}'\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def context_filtering(contexts):\n",
    "        contexts_v = []\n",
    "        contexts_c = []\n",
    "\n",
    "        for item in contexts:\n",
    "            if item['type'] in ['video', 'wiki', 'email', 'error']:\n",
    "                contexts_v.append(item)\n",
    "            elif item['type'] in ['creo_view', 'creo_parametric']:\n",
    "                contexts_c.append(item)\n",
    "        if len(contexts_v) == 0:\n",
    "            contexts = contexts_c[:4]\n",
    "        elif len(contexts_v) == 1:\n",
    "            contexts = contexts_v + contexts_c[:3]\n",
    "        elif len(contexts_v) == 2:\n",
    "            contexts = contexts_v[:2] + contexts_c[:2]\n",
    "        elif len(contexts_v) == 3:\n",
    "            contexts = contexts_v[:3] + contexts_c[:1]\n",
    "        elif len(contexts_v) > 3:\n",
    "            contexts = contexts_v[:4]# + contexts_c[:1]\n",
    "\n",
    "        priority_order = ['video', 'wiki', 'email','error', 'creo_parametric', 'creo_view'] \n",
    "        contexts = sorted(contexts, key=lambda x: priority_order.index(x['type']))\n",
    "        return contexts\n",
    "    \n",
    "    async def check_answer(self,query, context):\n",
    "        system_prompt = f\"\"\"\n",
    " **Task:** You will be provided with a small chunk of document or transcript.\n",
    "  **Objective:** Determine if the given query, can be answered using the chunk of document.\n",
    "  **Instructions:**\n",
    "  1. **Strict Evaluation:** Review the chunk of document carefully. Assess whether the information within it directly addresses the query.\n",
    "  2. **Binary Response:**\n",
    "    - Respond with **\"Yes\"** if the chunk of document contains sufficient information to answer the query.\n",
    "    - Respond with **\"No\"** if the chunk of document does not contain sufficient information to answer the query or any part of it.\n",
    "  3. **No Further Explanation:** Provide only the binary response (\"Yes\" or \"No\"). Do not include any additional explanation, reasoning, or details.\n",
    "  \n",
    "  \n",
    "  **query**: {query}\n",
    "\n",
    "  \n",
    "  **Chunk of document**:\\n\\n{context}\n",
    "\"\"\"\n",
    "        inst_client = instructor.from_openai(await init_openai_client())\n",
    "\n",
    "        response = await inst_client.chat.completions.create(\n",
    "                model=\"ssagpt4omini\",\n",
    "                response_model=SinglePrediction,\n",
    "                messages=[{\"role\": \"system\", \"content\": system_prompt}],\n",
    "                temperature=0.0\n",
    "            )\n",
    "        \n",
    "        return response.class_label.name\n",
    "\n",
    "    \n",
    "    async def run_parallel_searches(self, query):  \n",
    "        tasks = [  \n",
    "            self.search(query, 3, self.get_filter_query(\"video\")),  \n",
    "            self.search(query, 3, self.get_filter_query(\"wiki\")),  \n",
    "            self.search(query, 2, self.get_filter_query(\"error\")),  \n",
    "            self.search(query, 2, self.get_filter_query(\"creo_view\")),  \n",
    "            self.search(query, 2, self.get_filter_query(\"creo_parametric\")),  \n",
    "        ]\n",
    "        contexts_video, contexts_wiki, contexts_error, contexts_creo_view, contexts_creo_parametric = await asyncio.gather(*tasks)\n",
    "\n",
    "        tasks_2 = [  \n",
    "            self.check_answer(query, contexts_video),  \n",
    "            self.check_answer(query, contexts_wiki),  \n",
    "            self.check_answer(query, contexts_error),  \n",
    "            self.check_answer(query, contexts_creo_view),  \n",
    "            self.check_answer(query, contexts_creo_parametric),  \n",
    "        ]\n",
    "\n",
    "        ans_video, ans_wiki, ans_error, ans_creo_view, ans_creo_parametric = await asyncio.gather(*tasks_2)\n",
    "\n",
    "        context = []\n",
    "        if ans_video.upper() == \"YES\":\n",
    "            context = context + contexts_video\n",
    "        elif ans_wiki.upper() == \"YES\":\n",
    "            context = context + contexts_wiki\n",
    "        elif ans_error.upper() == \"YES\":\n",
    "            context = context + contexts_error\n",
    "        elif ans_creo_view.upper() == \"YES\":\n",
    "            context = context + contexts_creo_view\n",
    "        elif ans_creo_parametric.upper() == \"YES\":\n",
    "            context = context + contexts_creo_parametric\n",
    "        else:\n",
    "            context = []\n",
    "        \n",
    "\n",
    "        return context\n",
    "\n",
    "    async def get_prompt_message(self, query: str, top: int = 3, rag_filter = None) -> (List[Any], str):\n",
    "\n",
    "        if rag_filter == 'error': \n",
    "            contexts = await self.search(query, 3, self.get_filter_query(rag_filter))\n",
    "        else:\n",
    "            contexts = await self.run_parallel_searches(query)\n",
    "            # print(\"contexts:\\n\", contexts)\n",
    "\n",
    "        context_str = \"\\n\\n\".join(  \n",
    "            f\"**documents: {i+1}**\\n{context['chunk']}\" for i, context in enumerate(contexts)  \n",
    "        )\n",
    "        rag_user_query = f\"\"\"\n",
    "Context information is below.\n",
    "------------------------------------------\n",
    "{context_str}\n",
    "------------------------------------------\n",
    "\n",
    "\n",
    "**Query:** \n",
    "{query}\n",
    "\"\"\" \n",
    "        rag_system_prompt = \"\"\"\n",
    "INSTRUCTIONS:\n",
    "1. You are an assistant who helps users answer their queries.\n",
    "2. Always Answer the user's query from the Context. The user will provide context in the form of multiple documents, each identified by a document number. If a document is a transcript, it will also include timestamps in the format HH:MM:SS on each line above the text.\n",
    "3. Give answer in step by step format.\n",
    "4. Keep your answer concise and solely on the information given in the Context.\n",
    "5. Always provide the answer with all relevant citations only when the answer is complete, ensuring that each citation includes the corresponding timestamp and document number used to generate the response. Provide the citation in the following format only at the end of the whole answer not in between the answer.\n",
    "    - For transcript, use: [timestamp, documents number]. for example [[\"00:11:00\", \"1\"], [\"00:1:44\", \"2\"]]\n",
    "    - For non transcript, use: [\"\", documents number]. for example [[\"\", \"3\"],[\"\", \"1\"], [\"\", \"2\"]]\n",
    "    - For chit-chat query citation will be empty [[]]\n",
    "6. Do not create or derive your own answer. If the answer is not directly available in the context, just reply stating, 'There is no answer available'\n",
    "\"\"\"\n",
    "        messages = [{\"role\": \"system\", \"content\": rag_system_prompt},  \n",
    "                      {\"role\": \"user\", \"content\": rag_user_query}]\n",
    "        \n",
    "\n",
    "        return contexts, messages \n",
    "  \n",
    "    async def openai_with_retry(self, messages, tools, user_json, max_retries=3):\n",
    "          \n",
    "        inst_client = instructor.from_openai(await init_openai_client())\n",
    "        response = await inst_client.chat.completions.create(\n",
    "                model=\"ssagpt4o\",\n",
    "                response_model=AnswerCitation,\n",
    "                messages=messages,\n",
    "                temperature=0.05\n",
    "            )\n",
    "        return response.answer,  response.citations, None\n",
    "    # answer, citations, apim_request_id\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_and_convert(input_list, top=10):\n",
    "        try:  \n",
    "            def time_to_seconds(time_str):  \n",
    "                if not time_str:  \n",
    "                    return 0\n",
    "                if time_str == '':\n",
    "                    return 0\n",
    "                if time_str == 0:\n",
    "                    return 0\n",
    "                try:  \n",
    "                    h, m, s = map(int, time_str.split(':'))  \n",
    "                    return h * 3600 + m * 60 + s  \n",
    "                except ValueError:  \n",
    "                    return None  \n",
    "    \n",
    "            result = []  \n",
    "            for item in input_list:  \n",
    "                if isinstance(item, list): \n",
    "                    if len(item) == 1:  \n",
    "                        # Treat single element as the second element  \n",
    "                        try:  \n",
    "                            second_elem = int(item[0])  \n",
    "                            if 1 <= second_elem <= top:  \n",
    "                                result.append([second_elem])  \n",
    "                        except ValueError:  \n",
    "                            continue  \n",
    "                    elif len(item) == 2:\n",
    "                        first, second = item\n",
    "                        if first != \"\" and second != \"\":   \n",
    "                            # Determine which is the time and which is the integer  \n",
    "                            if isinstance(first, str) and ':' in first:  \n",
    "                                time_str, second_elem = first, second  \n",
    "                            else:  \n",
    "                                time_str, second_elem = second, first  \n",
    "        \n",
    "                            try:  \n",
    "                                second_elem = int(second_elem)  \n",
    "                                if 1 <= second_elem <= top:  \n",
    "                                    seconds = time_to_seconds(time_str)  \n",
    "                                    if seconds is not None:  \n",
    "                                        result.append([seconds, second_elem])  \n",
    "                            except ValueError:  \n",
    "                                continue\n",
    "                        else:\n",
    "                            if first == \"\":\n",
    "                                second_elem = int(second)\n",
    "                            elif second == \"\":\n",
    "                                second_elem = int(first)\n",
    "                            if 1 <= second_elem <= top:\n",
    "                                result.append([second_elem]) \n",
    "                else:  \n",
    "                    # Handle flat list elements  \n",
    "                    try:  \n",
    "                        second_elem = int(item)  \n",
    "                        if 1 <= second_elem <= top:  \n",
    "                            result.append([second_elem])  \n",
    "                    except ValueError:  \n",
    "                        continue  \n",
    "    \n",
    "            return result  \n",
    "    \n",
    "        except Exception as e:  \n",
    "            logging.error(\"An error occurred: %s\", e)  \n",
    "            return []\n",
    "    \n",
    "    @staticmethod  \n",
    "    def remove_duplicates_apart_and_sort(lst, seconds_apart=300):    \n",
    "        unique_lst = list(set(tuple(sublist) for sublist in lst))  \n",
    "        sorted_lst = sorted(unique_lst, key=lambda x: (x[1] if len(x) > 1 else float('inf'), x[0]))  \n",
    "            \n",
    "        sorted_lst = [list(item) for item in sorted_lst]\n",
    "        \n",
    "        if len(sorted_lst) <= 3:\n",
    "            seconds_apart = 60  \n",
    "        filtered_lst = []  \n",
    "        last_seen = {}  \n",
    "        for sublist in sorted_lst:  \n",
    "            if len(sublist) > 1:  \n",
    "                time, identifier = sublist  \n",
    "                if identifier not in last_seen or time - last_seen[identifier] >= seconds_apart:  \n",
    "                    filtered_lst.append(sublist)  \n",
    "                    last_seen[identifier] = time  \n",
    "            else:  \n",
    "                filtered_lst.append(sublist)  \n",
    "\n",
    "        return filtered_lst\n",
    "    \n",
    "    @staticmethod  \n",
    "    def is_video_link(url):  \n",
    "        video_extensions = ['mp4', 'mkv', 'avi', 'mov', 'wmv', 'flv', 'webm']  \n",
    "        extension = url.split('.')[-1]  \n",
    "        return extension in video_extensions\n",
    "    \n",
    "    @staticmethod  \n",
    "    def generate_base64_encoded_string(start_time_in_seconds):  \n",
    "        data = {  \n",
    "            \"referralInfo\": {  \n",
    "                \"referralApp\": \"StreamWebApp\",  \n",
    "                \"referralView\": \"ShareDialog-Link\",  \n",
    "                \"referralAppPlatform\": \"Web\",  \n",
    "                \"referralMode\": \"view\"  \n",
    "            },  \n",
    "            \"playbackOptions\": {  \n",
    "                \"startTimeInSeconds\": start_time_in_seconds  \n",
    "            }  \n",
    "        }  \n",
    "        json_string = json.dumps(data)  \n",
    "        base64_encoded = base64.b64encode(json_string.encode('utf-8')).decode('utf-8')  \n",
    "        return base64_encoded #\"&nav=\" +  base64_encoded \n",
    "  \n",
    "    # @staticmethod  \n",
    "    # def clean_url(url):  \n",
    "    #     clean_url = re.sub(r'([?&]nav=).*', '', url)  \n",
    "    #     if clean_url[-1] == '?' or clean_url[-1] == '&':  \n",
    "    #         clean_url = clean_url[:-1]  \n",
    "    #     return clean_url\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_query_params(url):  \n",
    "        parsed_url = urlparse(url)  \n",
    "        query_params = parse_qs(parsed_url.query)   \n",
    "        clean_url = urlunparse(parsed_url._replace(query=\"\"))  \n",
    "        return query_params, clean_url\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_query_params(url, params):  \n",
    "        url_parts = list(urlparse(url))   \n",
    "        query = dict(parse_qsl(url_parts[4]))   \n",
    "        for key, value in params.items():  \n",
    "            query[key] = value  \n",
    "        url_parts[4] = urlencode(query, doseq=True)  \n",
    "    \n",
    "        return urlunparse(url_parts)\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_seconds_to_hhmmss(seconds):  \n",
    "        hours = seconds // 3600  \n",
    "        minutes = (seconds % 3600) // 60  \n",
    "        seconds = seconds % 60  \n",
    "        return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_actual_citations(data, seconds_apart=300):  \n",
    "        data.sort(key=lambda x: (x['url_metadata'], x['start_time'] if x['start_time'] is not None else -1))  \n",
    "        filtered_data = []  \n",
    "        i = 0  \n",
    "    \n",
    "        while i < len(data):  \n",
    "            current = data[i]  \n",
    "            same_metadata = [current]  \n",
    "            i += 1  \n",
    "    \n",
    "            while i < len(data) and data[i]['url_metadata'] == current['url_metadata']:  \n",
    "                same_metadata.append(data[i])  \n",
    "                i += 1  \n",
    "    \n",
    "            if len(same_metadata) <= 3:  \n",
    "                seconds_apart = 60  \n",
    "    \n",
    "            filtered_metadata = []  \n",
    "            for element in same_metadata:  \n",
    "                if element['start_time'] is None:  \n",
    "                    if not any(e['url_metadata'] == element['url_metadata'] for e in filtered_metadata):  \n",
    "                        filtered_metadata.append(element)  \n",
    "                else:  \n",
    "                    if not filtered_metadata or filtered_metadata[-1]['start_time'] is None or element['start_time'] - filtered_metadata[-1]['start_time'] >= seconds_apart:  \n",
    "                        filtered_metadata.append(element)  \n",
    "    \n",
    "            filtered_data.extend(filtered_metadata)  \n",
    "    \n",
    "        return filtered_data\n",
    "    \n",
    "    def get_actual_citations(self, citations, contexts, top=10):\n",
    "        actual_citations = []\n",
    "        citations = self.validate_and_convert(citations, top)\n",
    "        if citations != []:\n",
    "            citations = self.remove_duplicates_apart_and_sort(citations)\n",
    "            for citation in citations:\n",
    "                start_time = None\n",
    "                index = citation[0] - 1\n",
    "                if len(citation) > 1:\n",
    "                    start_time = citation[0]\n",
    "                    index = citation[1] - 1\n",
    "                url_metadata = contexts[index]['url_metadata']\n",
    "                type_ = contexts[index]['type'] #todo\n",
    "                try:\n",
    "                    title = contexts[index]['file_name_metadata'].split('.')[0]\n",
    "                except:\n",
    "                    title = contexts[index]['title'].split('.')[0]\n",
    "                type = 'video' #contexts[index]['type'] #todo\n",
    "                if type == 'video' and start_time is not None:\n",
    "                    title = f\"{title} @ [{self.convert_seconds_to_hhmmss(start_time)}]\"\n",
    "                    if self.is_video_link(url_metadata):  \n",
    "                        timestamp_link = url_metadata + f\"#t={start_time}\"\n",
    "                    else:  \n",
    "                        decoded_timestamp = [self.generate_base64_encoded_string(start_time)]  \n",
    "                        params, url = self.extract_query_params(url_metadata)\n",
    "                        params['nav'] =  decoded_timestamp\n",
    "                        timestamp_link = self.add_query_params(url, params)\n",
    "                else:\n",
    "                    timestamp_link = url_metadata\n",
    "                actual_citations.append({  \n",
    "                    \"FileName\": title,  \n",
    "                    \"URL\": timestamp_link,  \n",
    "                    \"url_metadata\": url_metadata,\n",
    "                    \"start_time\": start_time,\n",
    "                    \"type\": type_\n",
    "                })\n",
    "            actual_citations = self.filter_actual_citations(actual_citations)\n",
    "            priority_order = ['video', 'wiki', 'email','error', 'creo_parametric', 'creo_view'] \n",
    "            actual_citations = sorted(actual_citations, key=lambda x: priority_order.index(x['type']))\n",
    "            actual_citations = [{k: d[k] for k in ('FileName', 'URL')} for d in actual_citations]\n",
    "        return actual_citations\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    async def rag(self, query: str,top: int = 3, request_headers= None, request_body = None, rag_filter = None):\n",
    "        user_json = None\n",
    "        if request_headers is not None and request_body is not None:\n",
    "            if (self.MS_DEFENDER_ENABLED):\n",
    "                authenticated_user_details = get_authenticated_user_details(request_headers)\n",
    "                conversation_id = request_body.get(\"conversation_id\", None)        \n",
    "                user_json = get_msdefender_user_json(authenticated_user_details, request_headers, conversation_id)\n",
    "\n",
    "        contexts, messages = await self.get_prompt_message(query, top, rag_filter)\n",
    "        tools = [openai.pydantic_function_tool(AnswerCitation)]\n",
    "        answer, citations, apim_request_id = await self.openai_with_retry(messages, tools, user_json, max_retries=3)\n",
    "        top = len(citations)\n",
    "        actual_citations = self.get_actual_citations(citations, contexts, top)\n",
    "\n",
    "        return actual_citations, answer, apim_request_id, user_json\n",
    "\n",
    "\n",
    "# async def main():  \n",
    "#     search_prompt_service = AzureSearchPromptService()  \n",
    "#     query = 'how to get cad into your workspace'  \n",
    "#     contexts, rag_system_prompt = await search_prompt_service.get_prompt_message(query, top=3)  \n",
    "#     return contexts, rag_system_prompt  \n",
    "  \n",
    "# # Run the main function  \n",
    "# contexts, rag_system_prompt = await main()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag _old\n",
    "\n",
    "\n",
    "import os  \n",
    "from urllib.parse import urlparse, parse_qs, urlunparse, urlencode, parse_qsl   \n",
    "from backend.openai_client import init_openai_client  \n",
    "from azure.identity.aio import DefaultAzureCredential  \n",
    "from azure.search.documents.aio import SearchClient  \n",
    "from azure.search.documents.models import QueryType, VectorizedQuery, QueryAnswerType, QueryCaptionType  \n",
    "from typing import List, Any\n",
    "from pydantic import BaseModel, Field\n",
    "import openai\n",
    "from backend.auth.auth_utils import get_authenticated_user_details\n",
    "from backend.security.ms_defender_utils import get_msdefender_user_json\n",
    "import json\n",
    "import logging\n",
    "import base64 \n",
    "import re \n",
    "# import asyncio\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "class AnswerCitation(BaseModel):\n",
    "    \"\"\" \n",
    "    Citations and Answer\n",
    "    \"\"\" \n",
    "    citation: List[List[str]] = Field(description=\"Always include all the citations. in case of no answer citation=[[]] \")\n",
    "    \n",
    "    answer: str = Field(description=\"Only include Answer, do not include any citations in this. In case of no answer, answer = 'There is no answer available'\") \n",
    "  \n",
    "class AzureSearchPromptService:  \n",
    "    def __init__(self):  \n",
    "        self.service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
    "        self.wiki_index = os.getenv(\"AZURE_SEARCH_INDEX_VIDEO\")  #AZURE_SEARCH_INDEX_VIDEO\n",
    "        self.embedding_model = os.environ.get(\"AZURE_OPENAI_EMBEDDING_NAME\")  \n",
    "        self.chat_model = os.environ.get(\"AZURE_OPENAI_MODEL\")\n",
    "        self.MS_DEFENDER_ENABLED = os.environ.get(\"MS_DEFENDER_ENABLED\", \"true\").lower() == \"true\"\n",
    "  \n",
    "    async def generate_embeddings(self, query, model):\n",
    "        azure_openai_client = await init_openai_client()\n",
    "        embeddings_response = await azure_openai_client.embeddings.create(model=model, input=query)\n",
    "        embedding = embeddings_response.data[0].embedding\n",
    "        return embedding\n",
    "    \n",
    "    async def generate_vector_query(self, query: str) -> VectorizedQuery:  \n",
    "        vector = await self.generate_embeddings(query, self.embedding_model)  \n",
    "        return VectorizedQuery(vector=vector, k_nearest_neighbors=3, fields=\"text_vector\")  \n",
    "  \n",
    "    async def search(self, query: str, top: int = 12, rag_filter_query = None) -> List[Any]:  \n",
    "        vector_filter_mode = None\n",
    "        if rag_filter_query is not None:\n",
    "            vector_filter_mode=\"preFilter\"\n",
    "        async with SearchClient(self.service_endpoint, self.wiki_index, DefaultAzureCredential()) as search_client:\n",
    "            vector_query = await self.generate_vector_query(query)  \n",
    "            contexts = await search_client.search(  \n",
    "                search_text=query,  \n",
    "                vector_queries=[vector_query],  \n",
    "                select=[\"title\", \"chunk\", \"url_metadata\", \"file_name_metadata\", \"type\"],  #todo\n",
    "                query_type=QueryType.SEMANTIC,\n",
    "                vector_filter_mode=vector_filter_mode,\n",
    "                filter=rag_filter_query,\n",
    "                semantic_configuration_name=\"semantic\",  \n",
    "                query_caption=QueryCaptionType.EXTRACTIVE,  \n",
    "                query_answer=QueryAnswerType.EXTRACTIVE,  \n",
    "                top=top  \n",
    "            )\n",
    "\n",
    "            return [context async for context in contexts]  \n",
    "        \n",
    "    @staticmethod\n",
    "    def get_filter_query(rag_filter):\n",
    "        return f\"type eq '{rag_filter}'\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def context_filtering(contexts):\n",
    "        contexts_v = []\n",
    "        contexts_c = []\n",
    "\n",
    "        for item in contexts:\n",
    "            if item['type'] in ['video', 'wiki', 'email', 'error']:\n",
    "                contexts_v.append(item)\n",
    "            elif item['type'] in ['creo_view', 'creo_parametric']:\n",
    "                contexts_c.append(item)\n",
    "        if len(contexts_v) == 0:\n",
    "            contexts = contexts_c[:4]\n",
    "        elif len(contexts_v) == 1:\n",
    "            contexts = contexts_v + contexts_c[:3]\n",
    "        elif len(contexts_v) == 2:\n",
    "            contexts = contexts_v[:2] + contexts_c[:2]\n",
    "        elif len(contexts_v) == 3:\n",
    "            contexts = contexts_v[:3] + contexts_c[:1]\n",
    "        elif len(contexts_v) > 3:\n",
    "            contexts = contexts_v[:4]# + contexts_c[:1]\n",
    "\n",
    "        priority_order = ['video', 'wiki', 'email','error', 'creo_parametric', 'creo_view'] \n",
    "        contexts = sorted(contexts, key=lambda x: priority_order.index(x['type']))\n",
    "        return contexts\n",
    "\n",
    "    async def get_prompt_message(self, query: str, top: int = 3, rag_filter = None) -> (List[Any], str):\n",
    "\n",
    "        if rag_filter == 'error': \n",
    "            contexts = await self.search(query, top, self.get_filter_query(rag_filter))\n",
    "        else:\n",
    "            contexts = await self.search(query, 5, None)\n",
    "            print(\"contexts:\\n\", contexts)\n",
    "            contexts = self.context_filtering(contexts)\n",
    "\n",
    "        context_str = \"\\n\\n\".join(  \n",
    "            f\"**documents: {i+1}**\\n{context['chunk']}\" for i, context in enumerate(contexts)  \n",
    "        )\n",
    "        rag_user_query = f\"\"\"\n",
    "Context information is below.\n",
    "------------------------------------------\n",
    "{context_str}\n",
    "------------------------------------------\n",
    "\n",
    "\n",
    "**Query:** \n",
    "{query}\n",
    "\"\"\" \n",
    "        rag_system_prompt = \"\"\"\n",
    "INSTRUCTIONS:\n",
    "1. You are an assistant who helps users answer their queries.\n",
    "2. Always Answer the user's query from the Context. The user will provide context in the form of multiple documents, each identified by a document number. If a document is a transcript, it will also include timestamps in the format HH:MM:SS on each line above the text.\n",
    "3. Give answer in step by step format.\n",
    "4. Keep your answer concise and solely on the information given in the Context.\n",
    "5. Always provide the answer with all relevant citations only when the answer is complete, ensuring that each citation includes the corresponding timestamp and document number used to generate the response. Provide the citation in the following format only at the end of the whole answer not in between the answer.\n",
    "    - For transcript, use: [timestamp, documents number]. for example [[\"00:11:00\", \"1\"], [\"00:1:44\", \"2\"]]\n",
    "    - For non transcript, use: [\"\", documents number]. for example [[\"\", \"3\"],[\"\", \"1\"], [\"\", \"2\"]]\n",
    "    - For chit-chat query citation will be empty [[]]\n",
    "7. Do not create or derive your own answer. If the answer is not directly available in the context, just reply stating, 'There is no answer available'\n",
    "8. Points to remember: The first document has the highest priority, with priority decreasing from the first to the last. Therefore, the last document has the lowest priority. If the higher-priority documents contain the complete answers, ignore the lower-priority ones while answering and in citation.\n",
    "\"\"\"\n",
    "        messages = [{\"role\": \"system\", \"content\": rag_system_prompt},  \n",
    "                      {\"role\": \"user\", \"content\": rag_user_query}]\n",
    "        \n",
    "\n",
    "        return contexts, messages \n",
    "  \n",
    "    async def openai_with_retry(self, messages, tools, user_json, max_retries=3):  \n",
    "        retries = 0  \n",
    "        while retries < max_retries:    \n",
    "            azure_openai_client = await init_openai_client()  \n",
    "            raw_rag_response = await azure_openai_client.chat.completions.with_raw_response.create(  \n",
    "                model=self.chat_model,  \n",
    "                messages=messages,  \n",
    "                tools=tools,  \n",
    "                temperature=0,  \n",
    "                user=user_json  \n",
    "            )  \n",
    "            rag_response = raw_rag_response.parse()  \n",
    "            apim_request_id = raw_rag_response.headers.get(\"apim-request-id\")\n",
    "            try:  \n",
    "                structure_response = json.loads(rag_response.choices[0].message.tool_calls[0].function.arguments)\n",
    "                answer = structure_response['answer']\n",
    "                citations = structure_response['citation']\n",
    "\n",
    "                return answer,citations, apim_request_id \n",
    "            except Exception as e:  \n",
    "                retries += 1  \n",
    "                print(f\"Attempt {retries} failed: {e}\")  \n",
    "                if retries >= max_retries:  \n",
    "                    return rag_response.choices[0].message.content, [], apim_request_id\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_and_convert(input_list, top=10):\n",
    "        try:  \n",
    "            def time_to_seconds(time_str):  \n",
    "                if not time_str:  \n",
    "                    return 0\n",
    "                if time_str == '':\n",
    "                    return 0\n",
    "                if time_str == 0:\n",
    "                    return 0\n",
    "                try:  \n",
    "                    h, m, s = map(int, time_str.split(':'))  \n",
    "                    return h * 3600 + m * 60 + s  \n",
    "                except ValueError:  \n",
    "                    return None  \n",
    "    \n",
    "            result = []  \n",
    "            for item in input_list:  \n",
    "                if isinstance(item, list): \n",
    "                    if len(item) == 1:  \n",
    "                        # Treat single element as the second element  \n",
    "                        try:  \n",
    "                            second_elem = int(item[0])  \n",
    "                            if 1 <= second_elem <= top:  \n",
    "                                result.append([second_elem])  \n",
    "                        except ValueError:  \n",
    "                            continue  \n",
    "                    elif len(item) == 2:\n",
    "                        first, second = item\n",
    "                        if first != \"\" and second != \"\":   \n",
    "                            # Determine which is the time and which is the integer  \n",
    "                            if isinstance(first, str) and ':' in first:  \n",
    "                                time_str, second_elem = first, second  \n",
    "                            else:  \n",
    "                                time_str, second_elem = second, first  \n",
    "        \n",
    "                            try:  \n",
    "                                second_elem = int(second_elem)  \n",
    "                                if 1 <= second_elem <= top:  \n",
    "                                    seconds = time_to_seconds(time_str)  \n",
    "                                    if seconds is not None:  \n",
    "                                        result.append([seconds, second_elem])  \n",
    "                            except ValueError:  \n",
    "                                continue\n",
    "                        else:\n",
    "                            if first == \"\":\n",
    "                                second_elem = int(second)\n",
    "                            elif second == \"\":\n",
    "                                second_elem = int(first)\n",
    "                            if 1 <= second_elem <= top:\n",
    "                                result.append([second_elem]) \n",
    "                else:  \n",
    "                    # Handle flat list elements  \n",
    "                    try:  \n",
    "                        second_elem = int(item)  \n",
    "                        if 1 <= second_elem <= top:  \n",
    "                            result.append([second_elem])  \n",
    "                    except ValueError:  \n",
    "                        continue  \n",
    "    \n",
    "            return result  \n",
    "    \n",
    "        except Exception as e:  \n",
    "            logging.error(\"An error occurred: %s\", e)  \n",
    "            return []\n",
    "    \n",
    "    @staticmethod  \n",
    "    def remove_duplicates_apart_and_sort(lst, seconds_apart=300):    \n",
    "        unique_lst = list(set(tuple(sublist) for sublist in lst))  \n",
    "        sorted_lst = sorted(unique_lst, key=lambda x: (x[1] if len(x) > 1 else float('inf'), x[0]))  \n",
    "            \n",
    "        sorted_lst = [list(item) for item in sorted_lst]\n",
    "        \n",
    "        if len(sorted_lst) <= 3:\n",
    "            seconds_apart = 60  \n",
    "        filtered_lst = []  \n",
    "        last_seen = {}  \n",
    "        for sublist in sorted_lst:  \n",
    "            if len(sublist) > 1:  \n",
    "                time, identifier = sublist  \n",
    "                if identifier not in last_seen or time - last_seen[identifier] >= seconds_apart:  \n",
    "                    filtered_lst.append(sublist)  \n",
    "                    last_seen[identifier] = time  \n",
    "            else:  \n",
    "                filtered_lst.append(sublist)  \n",
    "\n",
    "        return filtered_lst\n",
    "    \n",
    "    @staticmethod  \n",
    "    def is_video_link(url):  \n",
    "        video_extensions = ['mp4', 'mkv', 'avi', 'mov', 'wmv', 'flv', 'webm']  \n",
    "        extension = url.split('.')[-1]  \n",
    "        return extension in video_extensions\n",
    "    \n",
    "    @staticmethod  \n",
    "    def generate_base64_encoded_string(start_time_in_seconds):  \n",
    "        data = {  \n",
    "            \"referralInfo\": {  \n",
    "                \"referralApp\": \"StreamWebApp\",  \n",
    "                \"referralView\": \"ShareDialog-Link\",  \n",
    "                \"referralAppPlatform\": \"Web\",  \n",
    "                \"referralMode\": \"view\"  \n",
    "            },  \n",
    "            \"playbackOptions\": {  \n",
    "                \"startTimeInSeconds\": start_time_in_seconds  \n",
    "            }  \n",
    "        }  \n",
    "        json_string = json.dumps(data)  \n",
    "        base64_encoded = base64.b64encode(json_string.encode('utf-8')).decode('utf-8')  \n",
    "        return base64_encoded #\"&nav=\" +  base64_encoded \n",
    "  \n",
    "    # @staticmethod  \n",
    "    # def clean_url(url):  \n",
    "    #     clean_url = re.sub(r'([?&]nav=).*', '', url)  \n",
    "    #     if clean_url[-1] == '?' or clean_url[-1] == '&':  \n",
    "    #         clean_url = clean_url[:-1]  \n",
    "    #     return clean_url\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_query_params(url):  \n",
    "        parsed_url = urlparse(url)  \n",
    "        query_params = parse_qs(parsed_url.query)   \n",
    "        clean_url = urlunparse(parsed_url._replace(query=\"\"))  \n",
    "        return query_params, clean_url\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_query_params(url, params):  \n",
    "        url_parts = list(urlparse(url))   \n",
    "        query = dict(parse_qsl(url_parts[4]))   \n",
    "        for key, value in params.items():  \n",
    "            query[key] = value  \n",
    "        url_parts[4] = urlencode(query, doseq=True)  \n",
    "    \n",
    "        return urlunparse(url_parts)\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_seconds_to_hhmmss(seconds):  \n",
    "        hours = seconds // 3600  \n",
    "        minutes = (seconds % 3600) // 60  \n",
    "        seconds = seconds % 60  \n",
    "        return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_actual_citations(data, seconds_apart=300):  \n",
    "        data.sort(key=lambda x: (x['url_metadata'], x['start_time'] if x['start_time'] is not None else -1))  \n",
    "        filtered_data = []  \n",
    "        i = 0  \n",
    "    \n",
    "        while i < len(data):  \n",
    "            current = data[i]  \n",
    "            same_metadata = [current]  \n",
    "            i += 1  \n",
    "    \n",
    "            while i < len(data) and data[i]['url_metadata'] == current['url_metadata']:  \n",
    "                same_metadata.append(data[i])  \n",
    "                i += 1  \n",
    "    \n",
    "            if len(same_metadata) <= 3:  \n",
    "                seconds_apart = 60  \n",
    "    \n",
    "            filtered_metadata = []  \n",
    "            for element in same_metadata:  \n",
    "                if element['start_time'] is None:  \n",
    "                    if not any(e['url_metadata'] == element['url_metadata'] for e in filtered_metadata):  \n",
    "                        filtered_metadata.append(element)  \n",
    "                else:  \n",
    "                    if not filtered_metadata or filtered_metadata[-1]['start_time'] is None or element['start_time'] - filtered_metadata[-1]['start_time'] >= seconds_apart:  \n",
    "                        filtered_metadata.append(element)  \n",
    "    \n",
    "            filtered_data.extend(filtered_metadata)  \n",
    "    \n",
    "        return filtered_data\n",
    "    \n",
    "    def get_actual_citations(self, citations, contexts, top=10):\n",
    "        actual_citations = []\n",
    "        citations = self.validate_and_convert(citations, top)\n",
    "        if citations != []:\n",
    "            citations = self.remove_duplicates_apart_and_sort(citations)\n",
    "            for citation in citations:\n",
    "                start_time = None\n",
    "                index = citation[0] - 1\n",
    "                if len(citation) > 1:\n",
    "                    start_time = citation[0]\n",
    "                    index = citation[1] - 1\n",
    "                url_metadata = contexts[index]['url_metadata']\n",
    "                type_ = contexts[index]['type'] #todo\n",
    "                try:\n",
    "                    title = contexts[index]['file_name_metadata'].split('.')[0]\n",
    "                except:\n",
    "                    title = contexts[index]['title'].split('.')[0]\n",
    "                type = 'video' #contexts[index]['type'] #todo\n",
    "                if type == 'video' and start_time is not None:\n",
    "                    title = f\"{title} @ [{self.convert_seconds_to_hhmmss(start_time)}]\"\n",
    "                    if self.is_video_link(url_metadata):  \n",
    "                        timestamp_link = url_metadata + f\"#t={start_time}\"\n",
    "                    else:  \n",
    "                        decoded_timestamp = [self.generate_base64_encoded_string(start_time)]  \n",
    "                        params, url = self.extract_query_params(url_metadata)\n",
    "                        params['nav'] =  decoded_timestamp\n",
    "                        timestamp_link = self.add_query_params(url, params)\n",
    "                else:\n",
    "                    timestamp_link = url_metadata\n",
    "                actual_citations.append({  \n",
    "                    \"FileName\": title,  \n",
    "                    \"URL\": timestamp_link,  \n",
    "                    \"url_metadata\": url_metadata,\n",
    "                    \"start_time\": start_time,\n",
    "                    \"type\": type_\n",
    "                })\n",
    "            actual_citations = self.filter_actual_citations(actual_citations)\n",
    "            priority_order = ['video', 'wiki', 'email','error', 'creo_parametric', 'creo_view'] \n",
    "            actual_citations = sorted(actual_citations, key=lambda x: priority_order.index(x['type']))\n",
    "            actual_citations = [{k: d[k] for k in ('FileName', 'URL')} for d in actual_citations]\n",
    "        return actual_citations\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    async def rag(self, query: str,top: int = 3, request_headers= None, request_body = None, rag_filter = None):\n",
    "        user_json = None\n",
    "        if request_headers is not None and request_body is not None:\n",
    "            if (self.MS_DEFENDER_ENABLED):\n",
    "                authenticated_user_details = get_authenticated_user_details(request_headers)\n",
    "                conversation_id = request_body.get(\"conversation_id\", None)        \n",
    "                user_json = get_msdefender_user_json(authenticated_user_details, request_headers, conversation_id)\n",
    "\n",
    "        contexts, messages = await self.get_prompt_message(query, top, rag_filter)\n",
    "        tools = [openai.pydantic_function_tool(AnswerCitation)]\n",
    "        answer, citations, apim_request_id = await self.openai_with_retry(messages, tools, user_json, max_retries=3)\n",
    "        top = len(citations)\n",
    "        actual_citations = self.get_actual_citations(citations, contexts, top)\n",
    "\n",
    "        return actual_citations, answer, apim_request_id, user_json\n",
    "\n",
    "\n",
    "# async def main():  \n",
    "#     search_prompt_service = AzureSearchPromptService()  \n",
    "#     query = 'how to get cad into your workspace'  \n",
    "#     contexts, rag_system_prompt = await search_prompt_service.get_prompt_message(query, top=3)  \n",
    "#     return contexts, rag_system_prompt  \n",
    "  \n",
    "# # Run the main function  \n",
    "# contexts, rag_system_prompt = await main()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
